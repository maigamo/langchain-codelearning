![alt text](image/03.png)

## ğŸ“¥ è¿è¡Œå…¥å£ä¸åˆå§‹åŒ–

LangChain æ²¡æœ‰å•ä¸€çš„ç»å¯¹å…¥å£ï¼Œé€šè¿‡å¯¼å…¥ç›¸åº”çš„æ¨¡å—æ¥è¿è¡Œã€‚
ä¸€ä¸ªå…¸å‹çš„ä½¿ç”¨æµç¨‹ï¼š
```python
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
  
# åˆå§‹åŒ–è¯­è¨€æ¨¡å‹
llm = OpenAI(temperature=0.9)

# åˆ›å»ºæç¤ºæ¨¡æ¿
prompt = PromptTemplate(
Â  Â  input_variables=["product"],
Â  Â  template="What is a good name for a company that makes {product}?",
)

# åˆ›å»ºé“¾
chain = LLMChain(llm=llm, prompt=prompt)

# è¿è¡Œé“¾
result = chain.run(product="colorful socks")
```

æ¥é€æ­¥è§£æå„ä¸ªæ ¸å¿ƒç»„ä»¶çš„åˆå§‹åŒ–å’Œè°ƒç”¨é€»è¾‘ã€‚

## ğŸ” è¯­è¨€æ¨¡å‹ (LLM) åˆå§‹åŒ–ä¸è°ƒç”¨

### ä¸€ã€åˆå§‹åŒ–æµç¨‹

åˆ›å»ºä¸€ä¸ª LLM å®ä¾‹æ—¶ï¼Œå®é™…å‘ç”Ÿäº†ä»¥ä¸‹è°ƒç”¨ï¼š
1. è°ƒç”¨ `OpenAI` ç±»çš„æ„é€ å‡½æ•°
2. è¯¥å‡½æ•°ç»§æ‰¿è‡ª `BaseLLM`ï¼Œ`BaseLLM`åˆç»§æ‰¿è‡ª `BaseLanguageModel`
3. åœ¨ `BaseLanguageModel` ä¸­è®¾ç½®åŸºç¡€å±æ€§ï¼ˆå¦‚ cacheã€callbacks ç­‰ï¼‰
ä»£ç è·¯å¾„ï¼š`libs/core/langchain_core/language_models/base.py`
```python
class BaseLanguageModel(RunnableSerializable[LanguageModelInput, LanguageModelOutputVar], ABC):
Â  Â  """æ‰€æœ‰è¯­è¨€æ¨¡å‹çš„æŠ½è±¡åŸºç±»"""
Â  Â  cache: Union[BaseCache, bool, None] = Field(default=None, exclude=True)
Â  Â  verbose: bool = Field(default_factory=_get_verbosity, exclude=True, repr=False)
Â  Â  callbacks: Callbacks = Field(default=None, exclude=True)
Â  Â  tags: Optional[list[str]] = Field(default=None, exclude=True)
Â  Â  metadata: Optional[dict[str, Any]] = Field(default=None, exclude=True)
Â  Â  custom_get_token_ids: Optional[Callable[[str], list[int]]] = Field(default=None, exclude=True)
```

### äºŒã€è°ƒç”¨æµç¨‹
å½“ä½¿ç”¨ LLM ç”Ÿæˆæ–‡æœ¬æ—¶ï¼ˆå¦‚ `llm("What is the capital of France?")`ï¼‰ï¼š
1. é¦–å…ˆä¼šè°ƒç”¨ `BaseLanguageModel.invoke` æ–¹æ³•
2. è¯¥æ–¹æ³•ä¼šå°†è¾“å…¥è½¬æ¢ä¸º `PromptValue`
3. ç„¶åè°ƒç”¨ `generate_prompt` æ–¹æ³•
4. `generate_prompt` æ–¹æ³•ä¼šè°ƒç”¨ç‰¹å®š LLM å®ç°çš„ API æ¥å£ï¼ˆå¦‚ OpenAI APIï¼‰
5. è¿”å›çš„ç»“æœä¼šè¢«å¤„ç†å¹¶è¿”å›ç»™ç”¨æˆ·
### invokeæ–¹æ³•æ ¸å¿ƒé€»è¾‘å¦‚ä¸‹
```python
return (
    self.generate_prompt(
        [self._convert_input(input)],
        stop=stop,
        callbacks=config.get("callbacks"),
        tags=config.get("tags"),
        metadata=config.get("metadata"),
        run_name=config.get("run_name"),
        run_id=config.pop("run_id", None),
        **kwargs,
    )
    .generations[0][0]
    .text
)
```
1.  **è°ƒç”¨Â `self.generate_prompt(...)`**
    - è¿™æ˜¯è°ƒç”¨æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„å…³é”®æ–¹æ³•ã€‚
    - å…ˆæŠŠä¼ å…¥çš„æç¤ºè¯Â `input`ï¼ˆ`generate_prompt`Â æ–¹æ³•æ”¯æŒæ‰¹é‡è¾“å…¥ï¼‰Â è½¬æ¢æˆæ¨¡å‹èƒ½ç†è§£çš„æ ¼å¼ï¼›è¿™ä¸€æ­¥å¾ˆé‡è¦ï¼Œä¸åŒæ¨¡å‹æˆ–é“¾æ¡ï¼Œè¾“å…¥æ ¼å¼å¯èƒ½ä¸åŒï¼Œæ‰€ä»¥è¦ç»Ÿä¸€å¤„ç†ã€‚
     - ä¼ å…¥äº†è½¬æ¢å¥½çš„è¾“å…¥ã€åœæ­¢è¯ã€å›è°ƒã€æ ‡ç­¾ã€å…ƒæ•°æ®ã€è¿è¡Œåç§°å’Œ IDï¼Œä»¥åŠé¢å¤–å‚æ•°ã€‚
2.  **è°ƒç”¨`.generations.text`**
    - `generate_prompt`Â è¿”å›çš„ç»“æœæ˜¯ä¸€ä¸ªå¤æ‚å¯¹è±¡ï¼Œå› æ­¤é€šè¿‡`.generations[0][0]`Â å–ç¬¬ä¸€ä¸ªè¾“å…¥çš„ç¬¬ä¸€ä¸ªç”Ÿæˆç»“æœã€‚
    - `.text`Â åˆ™æ˜¯æœ€ç»ˆçš„çº¯æ–‡æœ¬å†…å®¹ã€‚

æ¨¡å‹æ˜¯æ ¹æ®ä¸åŒçš„å¤§æ¨¡å‹å±æ€§ï¼ˆå¦‚openaiï¼‰æ¥å®Œæˆåˆå§‹åŒ–ã€‚æ¨¡å‹çš„è°ƒç”¨å…³é”®æ˜¯å°†æç¤ºè¯ã€æ•°æ®ç­‰ç­‰æ•°æ®è½¬åŒ–æˆLLMèƒ½å¤Ÿç†è§£çš„æ ¼å¼å†å‘é€ï¼Œå¹¶å°†è¿”å›çš„å¤æ‚æ•°æ®å¤„ç†æˆæˆ‘ä»¬è¦çš„é¢„æœŸæ•°æ®å†è¿”å›ã€‚